{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pointMass\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"collected_data/20000HER2_pointMassObject-v0_Hidden_256l_2.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "replan_interval = 15\n",
    "lower_achieved_whole_state = True\n",
    "\n",
    "data = np.load(\"collected_data/20000HER2_pointMassObject-v0_Hidden_256l_2.npz\")\n",
    "obs = data['obs']\n",
    "ags = data['achieved_goals']\n",
    "if lower_achieved_whole_state:\n",
    "    higher_level_acts = data['full_positional_states']\n",
    "    #act_dim_higher = env.observation_space.spaces['full_positional_state'].shape[0]\n",
    "else:\n",
    "    higher_level_acts = data['controllable_achieved_goal']\n",
    "    #act_dim_higher = env.observation_space.spaces['controllable_achieved_goal'].shape[0]\n",
    "lower_level_acts = data['acts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ok, what do we want to do?\n",
    "# Q1 - DO we want to learn from one long thing, or multiple demos?\n",
    "# lets say we want to multiple demos.\n",
    "# then what are we doing? Sample random start and end, sample at intervals of replan_interval.\n",
    "# desired goal for higher level is the achieved goal of the final state oberveed\n",
    "# we want to create observation / action pairs of each set of obs separated by the replan interval\n",
    "# action is either the whole state, or just the controllable section depending on the flag.\n",
    "\n",
    "def sample_relay_batch(obs, ags, higher_level_acts, lower_level_acts, replan_interval = 15):\n",
    "    # first thing we need to do is sample a couple of trajectories\n",
    "    num_trajectories = 10\n",
    "    traj_indexes = np.random.choice(obs.shape[0], num_trajectories)\n",
    "\n",
    "    # then, in each trajectory take a random start and end\n",
    "    max_start_index = int(obs.shape[1]*0.2) # the start index can be anywhere in the first 20% of steps. \n",
    "    end_indices = np.arange(int(obs.shape[1]*0.8), obs.shape[1]) # the end indice can be anywhere in the last 20% of steps\n",
    "    traj_start_indices = np.random.choice(max_start_index, num_trajectories)\n",
    "    traj_end_indices = np.random.choice(end_indices, num_trajectories)\n",
    "\n",
    "    # first things first, get it working using iterators - we can always optimise into matrix form later. \n",
    "    high_in_array = []\n",
    "    high_out_array = []\n",
    "    low_in_array = []\n",
    "    low_out_array = []\n",
    "\n",
    "    traj_obs = obs[traj_indexes]\n",
    "    for t in range(0,num_trajectories):\n",
    "        traj_obs = obs[traj_indexes][t]\n",
    "        traj_higher_level_acts = higher_level_acts[traj_indexes][t]\n",
    "        traj_ags = ags[traj_indexes][t]\n",
    "        traj_acts = lower_level_acts[traj_indexes][t]\n",
    "        replan_time_steps = np.arange(traj_start_indices[t],traj_end_indices[t],replan_interval)\n",
    "        # we want the higher level observations to be the obs at each higher level step\n",
    "        # we want the higher level action to be the achieved_goal of the corresponding next higher level step\n",
    "        # thats why we take 1: onwards for one, and up to the last one for the other.\n",
    "        high_obs = traj_obs[replan_time_steps[:-1]]\n",
    "        high_acts = traj_higher_level_acts[replan_time_steps[1:]]\n",
    "        # we also want the desired goal of the higher level, which is just the last ag\n",
    "        goal = traj_ags[-1]\n",
    "        # now tile it out so we have one for each higher level obs to later concat along the last dimension\n",
    "        high_desired_goals = np.tile(goal,[len(high_obs),1])\n",
    "        high_in = np.concatenate([high_obs, high_desired_goals], axis=-1)\n",
    "        # now, the lower level. We want each lower level ob to have desired goal of the corresponding next higher level act.\n",
    "        # obs is still obs.\n",
    "        # act is the baseline act. \n",
    "        # sample a lower_level obsfrom somewhere within the replan time window of each higher level step.\n",
    "        low_obs_indexes = replan_time_steps - np.random.choice(replan_interval, len(replan_time_steps))\n",
    "        low_obs = traj_obs[low_obs_indexes]\n",
    "        low_goals = traj_higher_level_acts[replan_time_steps]\n",
    "        low_acts = traj_acts[low_obs_indexes]\n",
    "        low_in = np.concatenate([low_obs, low_goals], axis = -1)\n",
    "\n",
    "\n",
    "        # add to the arrays\n",
    "        high_in_array.append(high_in)\n",
    "        high_out_array.append(high_acts)\n",
    "        low_in_array.append(low_in)\n",
    "        low_out_array.append(low_acts)\n",
    "\n",
    "    return np.concatenate(high_in_array), np.concatenate(high_out_array), np.concatenate(low_in_array), np.concatenate(low_out_array)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # then, between the start and end take a transition every replan_interval steps\n",
    "    \n",
    "    \n",
    "    \n",
    "high_in, high_out, low_in, low_out = sample_relay_batch(obs, ags, higher_level_acts, lower_level_acts, replan_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acts',\n",
       " 'obs',\n",
       " 'desired_goals',\n",
       " 'achieved_goals',\n",
       " 'controllable_achieved_goals',\n",
       " 'full_positional_states']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closing\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeding\n",
      "Environment set to sparse reward\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'observation': array([2.0300024, 2.99292  , 0.       , 0.       ], dtype=float32),\n",
       " 'achieved_goal': array([2.0300024, 2.99292  ], dtype=float32),\n",
       " 'desired_goal': array([ 1.0095205 , -0.76843745], dtype=float32),\n",
       " 'extra_info': None,\n",
       " 'controllable_achieved_goal': array([2.0300024, 2.99292  ], dtype=float32),\n",
       " 'full_positional_state': array([2.0300024, 2.99292  ], dtype=float32),\n",
       " 'image': array([[[236, 236, 236],\n",
       "         [234, 234, 234],\n",
       "         [232, 232, 232],\n",
       "         ...,\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227]],\n",
       " \n",
       "        [[235, 235, 235],\n",
       "         [233, 233, 233],\n",
       "         [232, 232, 232],\n",
       "         ...,\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227]],\n",
       " \n",
       "        [[235, 235, 235],\n",
       "         [233, 233, 233],\n",
       "         [232, 232, 232],\n",
       "         ...,\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         ...,\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227]],\n",
       " \n",
       "        [[227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         ...,\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227]],\n",
       " \n",
       "        [[227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         ...,\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227],\n",
       "         [227, 227, 227]]], dtype=uint8)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('pointMass-v0')\n",
    "env.render(mode='human')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "replan_interval = 15\n",
    "lower_achieved_whole_state = True\n",
    "#data = np.load(\"collected_data/20000HER2_pointMassObject-v0_Hidden_256l_2.npz\")\n",
    "data = np.load(\"collected_data/10000HER2_pointMass-v0_Hidden_256l_2.npz\")\n",
    "obs = data['obs']\n",
    "ags = data['achieved_goals']\n",
    "if lower_achieved_whole_state:\n",
    "    higher_level_acts = data['full_positional_states']\n",
    "    #act_dim_higher = env.observation_space.spaces['full_positional_state'].shape[0]\n",
    "else:\n",
    "    higher_level_acts = data['controllable_achieved_goals']\n",
    "    #act_dim_higher = env.observation_space.spaces['controllable_achieved_goal'].shape[0]\n",
    "lower_level_acts = data['acts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first thing we need to do is sample a couple of trajectories\n",
    "num_trajectories = 10\n",
    "traj_indexes = np.random.choice(obs.shape[0], num_trajectories)\n",
    "\n",
    "# then, in each trajectory take a random start and end\n",
    "max_start_index = int(obs.shape[1]*0.2) # the start index can be anywhere in the first 20% of steps. \n",
    "end_indices = np.arange(int(obs.shape[1]*0.8), obs.shape[1]) # the end indice can be anywhere in the last 20% of steps\n",
    "traj_start_indices = np.random.choice(max_start_index, num_trajectories)\n",
    "traj_end_indices = np.random.choice(end_indices, num_trajectories)\n",
    "\n",
    "# first things first, get it working using iterators - we can always optimise into matrix form later. \n",
    "high_in_array = []\n",
    "high_out_array = []\n",
    "low_in_array = []\n",
    "low_out_array = []\n",
    "\n",
    "t = 0\n",
    "traj_obs = obs[traj_indexes][t]\n",
    "traj_higher_level_acts = higher_level_acts[traj_indexes][t]\n",
    "traj_ags = ags[traj_indexes][t]\n",
    "traj_acts = lower_level_acts[traj_indexes][t]\n",
    "replan_time_steps = np.arange(traj_start_indices[t],traj_end_indices[t],replan_interval)\n",
    "# we want the higher level observations to be the obs at each higher level step\n",
    "    # we want the higher level action to be the achieved_goal of the corresponding next higher level step\n",
    "# thats why we take 1: onwards for one, and up to the last one for the other.\n",
    "high_obs = traj_obs[replan_time_steps[:-1]]\n",
    "high_acts = traj_higher_level_acts[replan_time_steps[1:]]\n",
    "# we also want the desired goal of the higher level, which is just the last ag\n",
    "goal = traj_ags[-1]\n",
    "# now tile it out so we have one for each higher level obs to later concat along the last dimension\n",
    "high_desired_goals = np.tile(goal,[len(high_obs),1])\n",
    "high_in = np.concatenate([high_obs, high_desired_goals], axis=-1)\n",
    "# now, the lower level. We want each lower level ob to have desired goal of the corresponding next higher level act.\n",
    "# obs is still obs.\n",
    "# act is the baseline act. \n",
    "# sample a lower_level obsfrom somewhere within the replan time window of each higher level step.\n",
    "low_obs_indexes = replan_time_steps - np.random.choice(replan_interval, len(replan_time_steps))\n",
    "low_obs = traj_obs[low_obs_indexes]\n",
    "low_goals = traj_higher_level_acts[replan_time_steps]\n",
    "low_acts = traj_acts[low_obs_indexes]\n",
    "low_in = np.concatenate([low_obs, low_goals], axis = -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initing\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9290dc6e1c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_start_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraj_ags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msub_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraj_higher_level_acts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mreplan_interval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msub_g2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraj_ags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mreplan_interval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "import time\n",
    "env.reset_goal_pos(goal)\n",
    "for i in range(0,150):\n",
    "    o = traj_obs[i]\n",
    "    env.initialize_start_pos(o) \n",
    "    ag = traj_ags[i]\n",
    "    sub_g = traj_higher_level_acts[i+replan_interval]\n",
    "    \n",
    "    sub_g2 = traj_ags[i+replan_interval]\n",
    "    \n",
    "    env.visualise_sub_goal(sub_g, lower_achieved_whole_state)\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_sub_goal(self, sub_goal, lower_achieved_whole_state):\n",
    "    \n",
    "\n",
    "    # in the sub_goal case we either only  have the positional info, or we have the full state positional info.\n",
    "    #print(sub_goal)\n",
    "    index = 0\n",
    "    if self.sub_goals is None:\n",
    "        self.sub_goals = []\n",
    "        self.sub_goal_cids = []\n",
    "        print('initing')\n",
    "        sphereRadius = 0.3\n",
    "        mass = 1\n",
    "        colSphereId = self._p.createCollisionShape(p.GEOM_SPHERE, radius=sphereRadius)\n",
    "        relativeChildPosition = [0, 0, 0]\n",
    "        relativeChildOrientation = [0, 0, 0, 1]\n",
    "        alpha = 0.5\n",
    "        colors = [[212/250,175/250,55/250,alpha], [1,1,0,alpha], [0,0,1,alpha]]\n",
    "\n",
    "\n",
    "        for g in range(0, len(sub_goal)//2):\n",
    "            if g == 0:\n",
    "                # the sphere\n",
    "                visId = p.createVisualShape(p.GEOM_SPHERE, radius = sphereRadius,\n",
    "                                                 rgbaColor=colors[g])\n",
    "            else:\n",
    "                visId = p.createVisualShape(p.GEOM_BOX, halfExtents=[0.35,0.35,0.35],\n",
    "                                                 rgbaColor=colors[g])\n",
    "\n",
    "            self.sub_goals.append(self._p.createMultiBody(mass, colSphereId, visId, [sub_goal[index], sub_goal[index + 1], 0.1]))\n",
    "            collisionFilterGroup = 0\n",
    "            collisionFilterMask = 0\n",
    "            self._p.setCollisionFilterGroupMask(self.sub_goals[g], -1, collisionFilterGroup, collisionFilterMask)\n",
    "            self.sub_goal_cids.append(\n",
    "                self._p.createConstraint(self.sub_goals[g], -1, -1, -1, self._p.JOINT_FIXED, [sub_goal[index], sub_goal[index + 1], 0.1], [0, 0, 0.1],\n",
    "                                         relativeChildPosition, relativeChildOrientation))\n",
    "            index +=2\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        for g in range(0, len(sub_goal)//2):\n",
    "            \n",
    "            self._p.resetBasePositionAndOrientation(self.sub_goals[g], [sub_goal[index], sub_goal[index + 1], 0.1],\n",
    "                                                    [0, 0, 0, 1])\n",
    "            self._p.changeConstraint(self.sub_goal_cids[g], [sub_goal[index], sub_goal[index + 1], 0.1], maxForce=100)\n",
    "            index += 2\n",
    "\n",
    "    \n",
    "env.visualise_sub_goal = visualise_sub_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "env.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acts',\n",
       " 'obs',\n",
       " 'desired_goals',\n",
       " 'achieved_goals',\n",
       " 'controllable_achieved_goals',\n",
       " 'full_positional_states']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([data['obs'], data['desired_goals']], axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.random.choice(data['obs'].shape[0], 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 9, 3, 6, 1, 3, 7, 5, 5, 9, 5, 2, 1, 5, 5, 9, 5, 9, 0, 8, 0,\n",
       "       5, 3, 7, 0, 9, 0, 2, 5, 1, 8, 6, 6, 5, 8, 9, 1, 0, 1, 4, 3, 0, 3,\n",
       "       5, 8, 0, 7, 2, 1, 4, 2, 6, 6, 8, 5, 9, 2, 1, 7, 6, 5, 2, 4, 6, 1,\n",
       "       4, 7, 4, 3, 1, 9, 0, 9, 0, 6, 3, 6, 6, 5, 4, 3, 8, 8, 8, 6, 8, 4,\n",
       "       8, 0, 8, 3, 6, 1, 2, 2, 3, 4, 6, 5, 2, 4, 4, 8, 3, 4, 8, 1, 9, 9,\n",
       "       6, 1, 1, 0, 9, 4, 4, 6, 6, 8, 9, 8, 3, 3, 0, 7, 9, 7, 5, 0, 6, 8,\n",
       "       2, 0, 4, 7, 2, 7, 1, 0, 9, 7, 6, 1, 7, 0, 7, 6, 7, 2, 0, 1, 3, 7,\n",
       "       0, 1, 6, 4, 5, 0, 3, 7, 5, 2, 6, 3, 1, 7, 5, 0, 3, 8, 2, 3, 1, 9,\n",
       "       7, 0, 7, 3, 1, 6, 1, 2, 9, 5, 7, 6, 2, 9, 3, 9, 7, 7, 7, 9, 0, 0,\n",
       "       1, 5, 0, 1, 6, 7, 2, 9, 0, 4, 7, 8, 6, 7, 4, 9, 5, 6, 2, 5, 9, 9,\n",
       "       5, 8, 1, 7, 2, 2, 6, 1, 5, 0, 6, 5, 5, 3, 6, 6, 8, 7, 1, 2, 7, 5,\n",
       "       8, 6, 5, 6, 6, 4, 4, 4, 5, 0, 5, 0, 0, 7, 3, 2, 1, 5, 7, 1, 8, 1,\n",
       "       3, 5, 4, 4, 3, 3, 3, 1, 3, 5, 0, 5, 8, 9, 5, 6, 9, 1, 4, 8, 6, 6,\n",
       "       6, 6, 9, 3, 4, 8, 8, 5, 5, 7, 6, 7, 7, 8, 1, 1, 3, 5, 5, 2, 8, 2,\n",
       "       0, 1, 6, 0, 4, 7, 7, 7, 0, 6, 9, 1, 5, 8, 6, 7, 6, 0, 9, 7, 6, 7,\n",
       "       6, 1, 6, 6, 8, 1, 6, 5, 5, 7, 0, 6, 2, 6, 4, 2, 9, 6, 8, 4, 4, 5,\n",
       "       0, 4, 1, 5, 3, 4, 4, 3, 3, 0, 7, 3, 1, 7, 7, 3, 0, 0, 5, 0, 3, 9,\n",
       "       8, 1, 2, 3, 6, 8, 0, 0, 8, 6, 9, 6, 4, 2, 8, 0, 5, 5, 1, 2, 8, 5,\n",
       "       0, 2, 1, 3, 7, 9, 7, 1, 0, 2, 4, 7, 3, 7, 1, 7, 7, 1, 3, 4, 5, 6,\n",
       "       8, 6, 4, 6, 1, 2, 6, 2, 7, 5, 7, 0, 0, 3, 4, 4, 5, 0, 5, 2, 9, 0,\n",
       "       8, 9, 3, 9, 0, 9, 0, 9, 8, 1, 5, 9, 5, 2, 7, 0, 1, 8, 0, 2, 8, 1,\n",
       "       8, 0, 8, 0, 3, 0, 4, 2, 9, 8, 8, 6, 6, 1, 7, 0, 7, 3, 8, 4, 6, 6,\n",
       "       6, 9, 0, 5, 7, 3, 2, 3, 4, 5, 7, 5, 3, 3, 9, 7, 7, 6, 3, 2, 2, 2,\n",
       "       3, 9, 0, 4, 1, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.random.choice(5, [10,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 3],\n",
       "       [3, 4, 1],\n",
       "       [0, 2, 2],\n",
       "       [2, 3, 0],\n",
       "       [1, 4, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 2],\n",
       "       [1, 1, 4],\n",
       "       [2, 3, 1],\n",
       "       [1, 3, 2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = data['obs']\n",
    "acts = data['acts']\n",
    "\n",
    "train_length = int(0.8 * (len(obs)))\n",
    "train_obs,train_acts  = obs[:train_length, :,:], acts[:train_length, :,:]\n",
    "valid_obs,  valid_acts  = obs[train_length:, :,:], acts[train_length:, :,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 0 4 6]\n"
     ]
    }
   ],
   "source": [
    "sequences = np.random.choice(len(train_obs), 5)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[sequences].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(obs,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
